llm:
  provider: "openai" #"openai" #"ollama"
  model_id: gemini-2.5-flash-preview-04-17 #"ollama_chat/qwen3:235b" #"gemini-2.5-flash-preview-04-17" #"gemini-2.5-flash-preview-04-17" #"Llama 3.3 70b Instruct AWQ" # Llama-3.3-70b-Instruct-AWQ #"gemini-2.5-flash-preview-04-17" # "Llama-3.3-70b-Instruct-AWQ" # "gemini-2.5-flash-preview-04-17" #"deepseek-chat" #"ollama_chat/qwen3:32b" #ollama_chat/qwen3:14b #"gemini-2.0-flash" #"ollama_chat/qwen3:32b" #Qwen/Qwen3-14B" #ollama_chat/qwen3:14b
  provider_kwargs:
    transformers:
      device_map: "auto" # Example
      # torch_dtype: "auto" # Example
      max_new_tokens: 128000
    ollama:
        # torch_dtype: "auto" # Example
        api_base: "http://localhost:11434"
        num_ctx: 128000
    openai:
      max_new_tokens: 32768
      api_base: "https://generativelanguage.googleapis.com/v1beta/openai/" #"https://willma.liza.surf.nl/api/v0/" #"https://generativelanguage.googleapis.com/v1beta/openai/" #"https://api.deepseek.com" # "https://willma.liza.surf.nl/api/v0"
      api_key: "GEMINI_API_KEY" #"GEMINI_API_KEY" #"AI_HUB_KEY" #"GEMINI_API_KEY" # "DEEPSEEK_API_KEY" # 

agent:
  max_steps: 50
  stream_outputs: true
  additional_authorized_imports: #unused right now
    - null
  #sub_agents: ["browsing", "pdf_opening", "file_searching", "data_inspecting", "package_installing", "file_managing"] # unused for now
  #orchestrator_agents: ["research_orchestrator", "environmentsetup_orchestrator", "dataingestionvalidation_orchestrator", "exploratorydataanalysis_orchestrator", "datapreprocessingfeatureengineering_orchestrator", "modeltraining_orchestrator", "hyperparameteroptimization_orchestrator", "modelevaluation_orchestrator", "reporting_orchestrator"] # orchestrator agent defines which sub agents are needed
  template_path: "./directives/root_orchestrator_template.md"

run:
  initial_prompt: "../configs/initial_prompt.txt" # Path to JSON file with initial prompt details
  agent_working_dir: "./"

